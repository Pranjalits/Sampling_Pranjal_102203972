{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGw8YnSQ9V9oI9xeRRDfi4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranjalits/Sampling_Pranjal_102203972/blob/main/Best_Sampling_Method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "data = pd.read_csv(\"/content/Creditcard_data.csv\")  # Replace with your dataset\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = data.drop(columns=[\"Class\"])\n",
        "y = data[\"Class\"]\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Define sampling techniques\n",
        "sampling_methods = {\n",
        "    \"Sampling1\": RandomOverSampler(random_state=42),\n",
        "    \"Sampling2\": RandomUnderSampler(random_state=42),\n",
        "    \"Sampling3\": SMOTE(random_state=42),\n",
        "    \"Sampling4\": SMOTETomek(random_state=42),\n",
        "    \"Sampling5\": ADASYN(random_state=42),\n",
        "}\n",
        "\n",
        "# Define machine learning models\n",
        "models = {\n",
        "    \"M1\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"M2\": RandomForestClassifier(random_state=42),\n",
        "    \"M3\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "    \"M4\": SVC(probability=True, random_state=42),\n",
        "    \"M5\": KNeighborsClassifier(),\n",
        "}\n",
        "\n",
        "# Create an empty results DataFrame\n",
        "results_df = pd.DataFrame(index=models.keys(), columns=sampling_methods.keys())\n",
        "\n",
        "# Apply sampling techniques and train models\n",
        "for sampling_name, sampler in sampling_methods.items():\n",
        "    # Apply sampling to training data\n",
        "    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        # Train model\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "\n",
        "        # Evaluate model on test set\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Store the accuracy in the results DataFrame\n",
        "        results_df.loc[model_name, sampling_name] = round(accuracy * 100, 2)  # Convert to percentage\n",
        "\n",
        "# Step 6: Determine the best sampling technique for each model\n",
        "best_sampling = results_df.idxmax(axis=1)  # Identify the sampling technique with the highest accuracy for each model\n",
        "results_df[\"Best_Sampling\"] = best_sampling  # Add a column for the best sampling technique\n",
        "\n",
        "# Display the updated results\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOgkKOLMhr2L",
        "outputId": "530e70dd-62f4-44ef-c7ea-f4d1abf050e8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:24:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:24:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:24:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:24:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:24:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Sampling1 Sampling2 Sampling3 Sampling4 Sampling5 Best_Sampling\n",
            "M1     91.81     57.76     93.53     92.67     92.67     Sampling3\n",
            "M2     99.14     66.81     98.71     98.71     99.14     Sampling1\n",
            "M3     98.71     31.47     98.28     98.28     99.14     Sampling5\n",
            "M4      87.5     74.57     43.53     43.53     43.97     Sampling1\n",
            "M5     97.84      75.0     72.41     73.71     72.84     Sampling1\n"
          ]
        }
      ]
    }
  ]
}